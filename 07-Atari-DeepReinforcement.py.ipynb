{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.layers import Dense,Conv2D,Flatten,Dropout\n",
    "import keras\n",
    "from collections import namedtuple\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = gym.make('SpaceInvaders-ramNoFrameskip-v0')\n",
    "env = gym.make('TimePilotNoFrameskip-v0')\n",
    "# env = gym.make(\"MsPacman-ramNoFrameskip-v0\")\n",
    "# env = gym.make('Zaxxon-v4')\n",
    "# env = gym.make(\"VideoPinball-ramNoFrameskip-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210, 160, 3)\n"
     ]
    }
   ],
   "source": [
    "# print(env.action_space.n)\n",
    "# print(env.observation_space)\n",
    "# print(env.observation_space.high)\n",
    "# print(env.observation_space.low)\n",
    "print(env.observation_space.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138, 160, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = env.reset()/255.0\n",
    "obs = obs[32:170,:]\n",
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# obs.shape\n",
    "obs=cv2.resize(obs,(50,50))\n",
    "# Cropping the image\n",
    "# obs = \n",
    "# obs = np.reshape(obs,(1,-1))\n",
    "# obs.shape\n",
    "plt.imshow(obs,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(obs):\n",
    "    obs = obs / 255.0\n",
    "    obs = cv2.resize(obs,(50,50))\n",
    "    \n",
    "    return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        1568      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 30976)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               3965056   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 3,986,410\n",
      "Trainable params: 3,986,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Neural Network\n",
    "model = keras.models.Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=4, strides=2,\n",
    "                 activation='relu', input_shape=(50,50,3)))\n",
    "model.add(Conv2D(filters=64, kernel_size=3, strides=1,\n",
    "                 activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dense(units=env.action_space.n))\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Experience Replay\n",
    "class Experience_Replay(object):\n",
    "    def __init(self,max_size=10000000):\n",
    "        self.memory  = []\n",
    "        self.max_size = max_size\n",
    "        self.mem_idx = 0\n",
    "    def store(self,experience):\n",
    "        self.memory.insert(self.mem_idx % self.max_size,experience)\n",
    "        self.mem_idx +=1\n",
    "    \n",
    "    def sample(self,batch_size):\n",
    "        assert batch_size <= len(self.memory), \"Sample size is more than Memory size\"\n",
    "        return random.sample(self.memory,batch_size)\n",
    "    def get_size(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE : I have to implement a method that will get batches from Experience Replay Memory and then Train NN on these batches\n",
    "Memory = Experience_Replay()\n",
    "def replay_experience(Memory,batch_size=50000):\n",
    "    batch = Memory.sample(batch_size)\n",
    "    train_on_batches(batch)\n",
    "    \n",
    "def train_on_batches(batch):\n",
    "    pass\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NUM_EPISODES = 10\n",
    "MAX_STEPS_PER_EPISODES = 200\n",
    "MAX_NUM_STEPS = MAX_NUM_EPISODES * MAX_STEPS_PER_EPISODES\n",
    "EPSILON_MIN = 0.005\n",
    "Epsilon_decacy = 500 * EPSILON_MIN / MAX_NUM_STEPS\n",
    "Alpha = 0.05\n",
    "Gamma = 0.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for episodes in range(MAX_NUM_EPISODES):\n",
    "        done = False\n",
    "        obs = env.reset()\n",
    "        obs = preprocess_image(obs)\n",
    "        total_reward = 0.0\n",
    "        step = 0\n",
    "        while not done:\n",
    "            env.render()\n",
    "            obs = np.expand_dims(obs,axis=0)\n",
    "            action = np.argmax(model.predict(obs))\n",
    "            if step == 0:\n",
    "                prev_action = action\n",
    "            next_state,reward,done,_ = env.step(action)\n",
    "            if action != prev_action:\n",
    "                print(action)\n",
    "            prev_action = action   \n",
    "            total_reward += reward\n",
    "            step += 1\n",
    "            obs = preprocess_image(next_state)\n",
    "        print('\\n Episode {} ended in {} Steps.Total reward {}'.format(episodes,step,total_reward))\n",
    "env.close ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
